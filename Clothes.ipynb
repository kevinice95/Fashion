{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fashion: By fabrics\n",
    "# Load Dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinice/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 174 of the file /Users/kevinice/anaconda2/lib/python2.7/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# https://www.words-to-use.com/words/clothing/ scraping\n",
    "page = requests.get('https://www.words-to-use.com/words/clothing/')\n",
    "data = page.text\n",
    "soup = BeautifulSoup(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = soup.find_all(id=\"types-of-clothes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text[0].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fabricslist = text.split('\\n')\n",
    "fabrics = filter(None,fabricslist)\n",
    "fabrics = [re.sub(' ','+',item) for item in fabrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'blazer',\n",
       " u'blouse',\n",
       " u'bra',\n",
       " u'camisole',\n",
       " u'capris',\n",
       " u'cardigan',\n",
       " u'casual+shirt',\n",
       " u'chinos',\n",
       " u'coat',\n",
       " u'corset',\n",
       " u'dress',\n",
       " u'dress+shirt',\n",
       " u'gown',\n",
       " u'scarf',\n",
       " u'shapewear',\n",
       " u'shirt',\n",
       " u'shorts',\n",
       " u'skirt',\n",
       " u'slacks',\n",
       " u'sleepwear',\n",
       " u'socks',\n",
       " u'stockings',\n",
       " u'suit',\n",
       " u'suspenders',\n",
       " u'sweater',\n",
       " u'sweater+set',\n",
       " u'hoodie',\n",
       " u'hose',\n",
       " u'hosiery',\n",
       " u'jacket',\n",
       " u'knit+top',\n",
       " u'leggings',\n",
       " u'lingerie',\n",
       " u'outerwear',\n",
       " u'pajamas',\n",
       " u'panties',\n",
       " u'pants',\n",
       " u'pjs',\n",
       " u'polo',\n",
       " u'swimwear',\n",
       " u't-shirt',\n",
       " u'tank',\n",
       " u'tank+top',\n",
       " u'tee',\n",
       " u'tie',\n",
       " u'tights',\n",
       " u'top',\n",
       " u'trousers',\n",
       " u'tunic',\n",
       " u'undershirt',\n",
       " u'underwear',\n",
       " u'undies']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fabrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('fiction.txt',header=None,engine='python',delimiter='\\t')\n",
    "for i in range(1,len(df.columns)-2):\n",
    "    curr = i\n",
    "    a = df.iloc[0,i].split(',')\n",
    "    df.iloc[0,i] = a[1]\n",
    "    if a[0] == '1800':\n",
    "        start = i\n",
    "data = pd.DataFrame(df.iloc[0,start:len(df.columns)-1])\n",
    "data = data.reset_index(drop=True)\n",
    "data = pd.concat([pd.Series(range(1800,2009)),data],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blazer\n",
      "blouse\n",
      "bra\n",
      "camisole\n",
      "capris\n",
      "cardigan\n",
      "casual+shirt\n",
      "chinos\n",
      "coat\n",
      "corset\n",
      "dress\n",
      "dress+shirt\n",
      "gown\n",
      "scarf\n",
      "shapewear\n",
      "shirt\n",
      "shorts\n",
      "skirt\n",
      "slacks\n",
      "sleepwear\n",
      "socks\n",
      "stockings\n",
      "suit\n",
      "suspenders\n",
      "sweater\n",
      "sweater+set\n",
      "hoodie\n",
      "hose\n",
      "hosiery\n",
      "jacket\n",
      "knit+top\n",
      "leggings\n",
      "lingerie\n",
      "outerwear\n",
      "pajamas\n",
      "panties\n",
      "pants\n",
      "pjs\n",
      "polo\n",
      "swimwear\n",
      "t-shirt\n",
      "tank\n",
      "tank+top\n",
      "tee\n",
      "tie\n",
      "tights\n",
      "top\n",
      "trousers\n",
      "tunic\n",
      "undershirt\n",
      "underwear\n",
      "undies\n"
     ]
    }
   ],
   "source": [
    "#Created the URL and will change the word substitute to desired word\n",
    "url = 'https://books.google.com/ngrams/graph?content=substitute&year_start=1800&year_end=2008&corpus=16&smoothing=0&share=&direct_url=t1%3B%2Csubstitute%3B%2Cc0'\n",
    "for fabric in fabrics:\n",
    "    print(fabric)\n",
    "    url1 = re.sub('substitute',fabric,url)\n",
    "    page = requests.get(url1)\n",
    "    text = page.text\n",
    "    soup = BeautifulSoup(text)\n",
    "    test = soup.find_all(type=\"text/javascript\")\n",
    "    test = test[4].get_text()\n",
    "    numbers = test[test.find(\": [\")+3:test.find(\"]\")]\n",
    "    temp = numbers.split(',')\n",
    "    if len(temp) < 100: \n",
    "        data[fabric] = 0\n",
    "        continue\n",
    "    temp = map(float,temp)\n",
    "    temp = pd.Series(temp)\n",
    "    data = pd.concat([data,temp],axis=1)\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"Year\"] + [\"Counts\"] + fabrics\n",
    "data1 = data\n",
    "data1.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinice/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "data1 = data1[:-1]\n",
    "data1.to_csv('fictionclothes%.csv',index=False)\n",
    "counts = data1\n",
    "for i in range(2,len(counts.columns)-1):\n",
    "    counts.iloc[:,i] = (counts.iloc[:,i] * counts.iloc[:,1].astype(float))\n",
    "counts.fillna(0)\n",
    "counts.to_csv('fictionclothesc.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36-test",
   "language": "python",
   "name": "py36-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
